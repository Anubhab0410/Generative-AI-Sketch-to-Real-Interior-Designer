{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPNFBl+nSzJ2uVjSPtKEwYn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anubhab0410/Generative-AI-Sketch-to-Real-Interior-Designer/blob/main/ControlNet_LoRA_FineTuning_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "usTsxygwMqU2"
      },
      "outputs": [],
      "source": [
        "# Install compatible versions for Colab's Python 3.12 environment\n",
        "!pip install -U diffusers transformers accelerate datasets\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "# We skip xformers for now to avoid the schema mismatch error you encountered"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "from diffusers import ControlNetModel, StableDiffusionControlNetPipeline, UniPCMultistepScheduler\n",
        "\n",
        "# 1. Mount Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Use your established path\n",
        "DRIVE_DATA_DIR = \"/content/drive/MyDrive/interior_design_dataset_A/content/interior_dataset\"\n",
        "\n",
        "# 3. Load Dataset\n",
        "dataset = load_dataset(\"json\", data_files=os.path.join(DRIVE_DATA_DIR, \"train.jsonl\"))\n",
        "\n",
        "def map_paths(example):\n",
        "    example[\"image\"] = os.path.join(DRIVE_DATA_DIR, example[\"image\"])\n",
        "    example[\"conditioning_image\"] = os.path.join(DRIVE_DATA_DIR, example[\"conditioning_image\"])\n",
        "    return example\n",
        "\n",
        "train_dataset = dataset['train'].map(map_paths)\n",
        "print(f\"âœ… Ready! Loaded {len(train_dataset)} pairs.\")"
      ],
      "metadata": {
        "id": "pUQAis6gOM5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Load Models\n",
        "controlnet = ControlNetModel.from_pretrained(\n",
        "    \"lllyasviel/sd-controlnet-canny\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "pipe = StableDiffusionControlNetPipeline.from_pretrained(\n",
        "    \"runwayml/stable-diffusion-v1-5\",\n",
        "    controlnet=controlnet,\n",
        "    torch_dtype=torch.float16\n",
        ").to(\"cuda\")\n",
        "\n",
        "# 5. Use Built-in PyTorch Speedup (Replaces xformers)\n",
        "pipe.enable_attention_slicing()\n",
        "pipe.scheduler = UniPCMultistepScheduler.from_config(pipe.scheduler.config)\n",
        "\n",
        "print(\"ðŸš€ Pipeline is live and GPU-accelerated.\")"
      ],
      "metadata": {
        "id": "QaQCjHaSOkcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Select a high-quality architectural sketch (Sample 150 is often cleaner)\n",
        "sample_idx = 150\n",
        "test_sketch = load_image(train_dataset[sample_idx]['conditioning_image'])\n",
        "\n",
        "# 2. Professional Prompt Engineering\n",
        "# Using specific IKEA-aesthetic keywords to trigger the fine-tuned weights\n",
        "prompt = (\n",
        "    \"A professional IKEA catalogue photo, Scandinavian minimalist interior, \"\n",
        "    \"light birch wood textures, soft natural daylight, high-end furniture, \"\n",
        "    \"8k UHD, architectural photography, neutral color palette, realistic shadows\"\n",
        ")\n",
        "negative_prompt = \"blurry, low quality, distorted furniture, messy, dark, noisy\"\n",
        "\n",
        "# 3. High-Fidelity Generation\n",
        "with torch.inference_mode():\n",
        "    result = pipe(\n",
        "        prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=test_sketch,\n",
        "        num_inference_steps=50, # Increased for smoother textures\n",
        "        controlnet_conditioning_scale=0.8, # Lets AI add realistic depth\n",
        "        guidance_scale=8.5 # Higher focus on the prompt\n",
        "    ).images[0]\n",
        "\n",
        "# 4. Final Comparison for Applicant A & B\n",
        "fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
        "ax[0].imshow(test_sketch, cmap='gray'); ax[0].set_title(\"Input Structural Guide (Applicant A)\")\n",
        "ax[1].imshow(result); ax[1].set_title(\"Final Fine-Tuned Interior (Applicant B)\")\n",
        "for a in ax: a.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "C8dQtU36PEBe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}