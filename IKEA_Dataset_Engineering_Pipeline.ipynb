{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMHlMoaCDKa8Nvyxq65HXSc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anubhab0410/Generative-AI-Sketch-to-Real-Interior-Designer/blob/main/IKEA_Dataset_Engineering_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWWiZD-yOBNR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "# Set your path to the downloaded repo\n",
        "dataset_path = 'ikea/images' # Adjust based on where you unzipped it\n",
        "output_photos = 'dataset/photos'\n",
        "output_sketches = 'dataset/sketches'\n",
        "\n",
        "os.makedirs(output_photos, exist_ok=True)\n",
        "os.makedirs(output_sketches, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "\n",
        "def process_ikea_dataset(input_folder, photo_folder, sketch_folder, size=(512, 512)):\n",
        "    # Find all jpg/png files\n",
        "    image_files = glob.glob(os.path.join(input_folder, '**/*.jpg'), recursive=True)\n",
        "\n",
        "    print(f\"Found {len(image_files)} images. Starting processing...\")\n",
        "\n",
        "    for i, img_path in enumerate(image_files):\n",
        "        # 1. Load and Resize Photo\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None: continue\n",
        "        img = cv2.resize(img, size)\n",
        "\n",
        "        # 2. Generate Canny Sketch\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        # We use a slight blur to prevent the sketch from being too 'noisy'\n",
        "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
        "        canny = cv2.Canny(blurred, 100, 200)\n",
        "\n",
        "        # 3. Save both with matching names\n",
        "        filename = f\"ikea_{i:04d}.png\"\n",
        "        cv2.imwrite(os.path.join(photo_folder, filename), img)\n",
        "        cv2.imwrite(os.path.join(sketch_folder, filename), canny)\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Processed {i} images...\")\n",
        "\n",
        "process_ikea_dataset(dataset_path, output_photos, output_sketches)"
      ],
      "metadata": {
        "id": "w1w2kGReO1HV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Check 3 random pairs\n",
        "fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
        "sample_files = os.listdir(PHOTO_DIR)[:3]\n",
        "\n",
        "for i, filename in enumerate(sample_files):\n",
        "    photo = Image.open(os.path.join(PHOTO_DIR, filename))\n",
        "    sketch = Image.open(os.path.join(SKETCH_DIR, filename))\n",
        "\n",
        "    axes[i, 0].imshow(photo)\n",
        "    axes[i, 0].set_title(\"Target Photo\")\n",
        "    axes[i, 1].imshow(sketch, cmap='gray')\n",
        "    axes[i, 1].set_title(\"Conditioning Sketch (Canny)\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r6yTEgZ3QwWl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cGfSkqOLSyXS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7eDphqlFRnk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# Re-defining paths (Ensure these match your previous cell)\n",
        "OUTPUT_DIR = '/content/interior_dataset'\n",
        "PHOTO_DIR = os.path.join(OUTPUT_DIR, 'photos')\n",
        "SKETCH_DIR = os.path.join(OUTPUT_DIR, 'sketches')\n",
        "\n",
        "# Verify the directory exists before listing\n",
        "if os.path.exists(PHOTO_DIR):\n",
        "    # Check 3 random pairs\n",
        "    fig, axes = plt.subplots(3, 2, figsize=(10, 15))\n",
        "    sample_files = os.listdir(PHOTO_DIR)[:3]\n",
        "\n",
        "    for i, filename in enumerate(sample_files):\n",
        "        photo = Image.open(os.path.join(PHOTO_DIR, filename))\n",
        "        sketch = Image.open(os.path.join(SKETCH_DIR, filename))\n",
        "\n",
        "        axes[i, 0].imshow(photo)\n",
        "        axes[i, 0].set_title(f\"Target Photo: {filename}\")\n",
        "        axes[i, 1].imshow(sketch, cmap='gray')\n",
        "        axes[i, 1].set_title(f\"Conditioning Sketch: {filename}\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Error: {PHOTO_DIR} does not exist. Please run the processing pipeline cell first.\")"
      ],
      "metadata": {
        "id": "klB_RbVQROwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/IvonaTau/ikea.git"
      ],
      "metadata": {
        "id": "bkl9QDnvQXxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# 1. Re-define paths to ensure they exist in this cell scope\n",
        "OUTPUT_DIR = '/content/interior_dataset'\n",
        "PHOTO_DIR = os.path.join(OUTPUT_DIR, 'photos')\n",
        "SKETCH_DIR = os.path.join(OUTPUT_DIR, 'sketches')\n",
        "METADATA_FILE = os.path.join(OUTPUT_DIR, 'train.jsonl')\n",
        "\n",
        "# 2. Generate the Metadata File\n",
        "if os.path.exists(PHOTO_DIR):\n",
        "    with open(METADATA_FILE, 'w') as f:\n",
        "        # Get list of all processed photos\n",
        "        filenames = sorted(os.listdir(PHOTO_DIR))\n",
        "\n",
        "        for filename in filenames:\n",
        "            # Create a dictionary for each image pair\n",
        "            # This follows the 'diffusers' library training format\n",
        "            entry = {\n",
        "                \"text\": \"a professional interior design of a room, IKEA style, high resolution\",\n",
        "                \"image\": f\"photos/{filename}\",\n",
        "                \"conditioning_image\": f\"sketches/{filename}\"\n",
        "            }\n",
        "            # Write as a single line in the JSONL file\n",
        "            f.write(json.dumps(entry) + '\\n')\n",
        "\n",
        "    print(f\"✅ Success! Metadata created with {len(filenames)} entries.\")\n",
        "    print(f\"Location: {METADATA_FILE}\")\n",
        "else:\n",
        "    print(\"❌ Error: Processed folders not found. Please run the Processing Pipeline cell again.\")"
      ],
      "metadata": {
        "id": "YZy4QqOXRoyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 1. MATCHING YOUR SIDEBAR: Input is '/content/ikea/images'\n",
        "INPUT_DIR = '/content/ikea/images'\n",
        "# Output will be created here\n",
        "OUTPUT_DIR = '/content/interior_dataset'\n",
        "PHOTO_DIR = os.path.join(OUTPUT_DIR, 'photos')\n",
        "SKETCH_DIR = os.path.join(OUTPUT_DIR, 'sketches')\n",
        "\n",
        "os.makedirs(PHOTO_DIR, exist_ok=True)\n",
        "os.makedirs(SKETCH_DIR, exist_ok=True)\n",
        "\n",
        "# 2. RUN THE PROCESSING\n",
        "image_paths = glob.glob(os.path.join(INPUT_DIR, '**/*.jpg'), recursive=True)\n",
        "print(f\"Found {len(image_paths)} images. Starting...\")\n",
        "\n",
        "for i, img_path in enumerate(tqdm(image_paths[:100])): # Start with 100 to test\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None: continue\n",
        "\n",
        "    img = cv2.resize(img, (512, 512))\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "    file_id = f\"ikea_{i:04d}.png\"\n",
        "    cv2.imwrite(os.path.join(PHOTO_DIR, file_id), img)\n",
        "    cv2.imwrite(os.path.join(SKETCH_DIR, file_id), edges)\n",
        "\n",
        "print(\"\\n✅ Done! Now try your visualization code again.\")"
      ],
      "metadata": {
        "id": "1WaIWByvSeQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Define the paths one last time\n",
        "OUTPUT_DIR = '/content/interior_dataset'\n",
        "PHOTO_DIR = os.path.join(OUTPUT_DIR, 'photos')\n",
        "METADATA_FILE = os.path.join(OUTPUT_DIR, 'train.jsonl')\n",
        "\n",
        "if os.path.exists(PHOTO_DIR):\n",
        "    filenames = sorted(os.listdir(PHOTO_DIR))\n",
        "    with open(METADATA_FILE, 'w') as f:\n",
        "        for filename in filenames:\n",
        "            entry = {\n",
        "                \"text\": \"a professional interior design of a room, IKEA style, high resolution\",\n",
        "                \"image\": f\"photos/{filename}\",\n",
        "                \"conditioning_image\": f\"sketches/{filename}\"\n",
        "            }\n",
        "            f.write(json.dumps(entry) + '\\n')\n",
        "    print(f\"✅ Metadata generated with {len(filenames)} entries!\")"
      ],
      "metadata": {
        "id": "6sQFafKCSz1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Clear the previous 100-entry test if you want a fresh start\n",
        "# !rm -rf /content/interior_dataset\n",
        "\n",
        "# 2. Re-run for the full dataset\n",
        "image_paths = glob.glob(os.path.join(INPUT_DIR, '**/*.jpg'), recursive=True)\n",
        "print(f\"Found {len(image_paths)} total images. Processing full dataset...\")\n",
        "\n",
        "for i, img_path in enumerate(tqdm(image_paths)): # Removed [:100]\n",
        "    # Check if this index was already processed (Optional)\n",
        "    file_id = f\"ikea_{i:04d}.png\"\n",
        "    if os.path.exists(os.path.join(PHOTO_DIR, file_id)):\n",
        "        continue\n",
        "\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None: continue\n",
        "\n",
        "    img = cv2.resize(img, (512, 512))\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    edges = cv2.Canny(gray, 100, 200)\n",
        "\n",
        "    cv2.imwrite(os.path.join(PHOTO_DIR, file_id), img)\n",
        "    cv2.imwrite(os.path.join(SKETCH_DIR, file_id), edges)\n",
        "\n",
        "print(f\"\\n✅ Done! Processed all {len(os.listdir(PHOTO_DIR))} images.\")"
      ],
      "metadata": {
        "id": "ESStloTVTVWX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Define the paths one last time\n",
        "OUTPUT_DIR = '/content/interior_dataset'\n",
        "PHOTO_DIR = os.path.join(OUTPUT_DIR, 'photos')\n",
        "METADATA_FILE = os.path.join(OUTPUT_DIR, 'train.jsonl')\n",
        "\n",
        "if os.path.exists(PHOTO_DIR):\n",
        "    filenames = sorted(os.listdir(PHOTO_DIR))\n",
        "    with open(METADATA_FILE, 'w') as f:\n",
        "        for filename in filenames:\n",
        "            entry = {\n",
        "                \"text\": \"a professional interior design of a room, IKEA style, high resolution\",\n",
        "                \"image\": f\"photos/{filename}\",\n",
        "                \"conditioning_image\": f\"sketches/{filename}\"\n",
        "            }\n",
        "            f.write(json.dumps(entry) + '\\n')\n",
        "    print(f\"✅ Metadata generated with {len(filenames)} entries!\")"
      ],
      "metadata": {
        "id": "uoYL_y5CTzx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this in a code cell to create a single zip file\n",
        "!zip -r interior_design_dataset_A.zip /content/interior_dataset"
      ],
      "metadata": {
        "id": "Pm5TQNBDT92f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}